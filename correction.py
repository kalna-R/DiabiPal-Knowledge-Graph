import json
import re

import pandas as pd
import numpy as np
from fuzzywuzzy import fuzz

import matplotlib.pyplot as plt
# library to create a network
import networkx as nx
from flask import jsonify


# function to read file
def readFile(path):
    # read data from the excel file
    dataframe = pd.read_csv(path)
    df = dataframe.fillna('')

    return df.astype(str)


# function to extract subject, relation and object for similar terms
def processSynonyms(row):
    subj = ''
    objct = ''
    relation = ''
    triple = []

    if row['Synonym'] != '':
        subj = row['TestName']
        objct = row['Synonym']
        relation = 'similar'

        triple = [subj.lower(), relation, objct.lower()]
        return triple
    else:
        return


# To-do- spelling corretion survice/service
# function to extract subject, relation and object for measurement unit
def processUnits(row):
    subj = ''
    objct = ''
    relation = ''
    triple = []

    if row['Unit'] != '':
        subj = row['TestName']
        objct = row['Unit']
        relation = 'unit'

        triple = [subj.lower(), relation, objct]
        # print(triple)
        return triple

    else:
        return


# function to extract subject, relation and object for ref range
def processRange(row):
    subj = ''
    objct = ''
    relation = ''
    triple = []

    if row['Range'] != '':
        subj = row['TestName']
        objct = row['Range']
        relation = 'range'

        triple = [subj.lower(), relation, objct]
        # print(triple)
        return triple

    else:
        return


# draw the knowledge graph
def printGraph(triples):
    # initialize graph object
    G = nx.MultiDiGraph()

    # automatically create nodes if they don't exist when adding an edge
    for triple in triples:
        G.add_edge(triple[0], triple[2], relation=triple[1])

    node_color = [G.degree(v) for v in G]
    node_size = [1500 * G.degree(v) for v in G]

    # k = distance between edges
    pos = nx.spring_layout(G, k=10)

    nx.draw(G, pos, edge_color='black', node_size=node_size, node_color=node_color, alpha=0.9,
            cmap=plt.cm.Blues, labels={node: node for node in G.nodes()})
    nx.draw_networkx_edge_labels(G, pos, label_pos=0.5, font_size=10, font_color='k', font_family='sans-serif',
                                 font_weight='normal')
    # plt.axis('off')
    # plt.show()

    return G


# function to find a node with a similar name or the same name
def hasNode(G, node):
    # node = name from the OCR array
    # check if the name is similar to a node

    # has_node returns true or false
    # if the test name is not in the graph, use Levenshtein algorithm to find similar terms
    if not G.has_node(node):
        print('Node not found. Checking for similar terms...')

        # list of nodes
        nodes_in_graph = G.nodes()

        for node_in_graph in nodes_in_graph:
            # ignores word order
            # if the ratio is above the threshold value, replace with the value from the knowledge graph
            ratio = fuzz.token_sort_ratio(node, node_in_graph)
            if ratio >= 80:
                node = node_in_graph
                print("Similar term found ", node)
                break

    node_in_edges = G.in_edges(nbunch=node, data='relation', keys=True)

    node_out_edges = G.out_edges(nbunch=node, data='relation', keys=True)

    return node_in_edges, node_out_edges


# word corrections
# data => output array of the ocr
def wordCorrection(G, data):
    # extract only alphabetic characters from the test name generated by the ocr
    name = " ".join(re.findall("[a-zA-Z]+", data['TEST NAME'].lower()))
    print("Test name from OCR: ", name)
    data["TEST NAME"] = name

    in_nodes, out_nodes = hasNode(G, name)

    if not in_nodes and not out_nodes:
        return {'Error': 'Unable to identify your report. Please try again'}
        # return json.dumps({'Error': 'Unable to identify your report type. Please try again'})

    if in_nodes:
        for u, v, keys, relation in in_nodes:
            # print("values for glucose", u, v)

            data['TEST NAME'] = u

            # units correction
            if relation == 'unit' and data['UNIT'] != v:
                data['UNIT'] = v

            # range correction
            if relation == 'range' and data['RANGE'] != v:
                data['RANGE'] = v

        # if data['RANGE'] != '' or data['UNIT'] != '':

    if out_nodes:
        for u1, v1, keys, relation in out_nodes:
            # print("values for glucose", u1, v1)

            data['TEST NAME'] = u1

            # units correction
            if relation == 'unit' and data['UNIT'] != v1:
                data['UNIT'] = v1

            # range correction
            if relation == 'range' and data['RANGE'] != v1:
                data['RANGE'] = v1

    return data


def post_process(ocr_array):
    # path to the dataset csv file which is published online
    path = r'https://docs.google.com/spreadsheets/d/e/2PACX-1vRFOFNO-1FTpeJc-u0vHtzh8VrO7cg4M19Nxff82FCc' \
           r'-QAA1lTTtLFXyuWzmKvsrUbkCPKuMEjdfC27/pub?output=csv '
    # dataframe of data
    df = readFile(path)

    triples = []

    # process row by row to find triples
    for index, row in df.iterrows():

        # identify synonyms
        synonyms = processSynonyms(row)
        if synonyms:
            triples.append(synonyms)

        # identify units
        units = processUnits(row)
        if units:
            triples.append(units)

        # identify ref ranges
        refRange = processRange(row)
        if refRange:
            triples.append(refRange)

        # nlp
        # processRowNLP(row)

    # execute the graph
    graph = printGraph(triples)

    out_array = wordCorrection(graph, ocr_array)

    # convert to json string
    # final_array = json.dumps(out_array)
    print("Final array", out_array)
    return out_array
